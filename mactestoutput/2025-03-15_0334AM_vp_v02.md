# Project: vp

## Table of Contents

- [../../../../../opt/caddy/html/reveal/public/wasm_spectrometer/src/lib.rs](#file-lib-rs)
- [../../../../../opt/caddy/html/reveal/public/wasm_spectrometer/pkg/wasm_spectrometer.js](#file-wasm-spectrometer-js)
- [../../../../../opt/caddy/html/reveal/public/wasm_spectrometer/index.html](#file-index-html)
- [../../../../../opt/caddy/html/reveal/public/wasm_spectrometer/Cargo.toml](#file-cargo-toml)

## File: ../../../../../opt/caddy/html/reveal/public/wasm_spectrometer/src/lib.rs <a id="file-lib-rs"></a>

```rust
use wasm_bindgen::prelude::*;
use wasm_bindgen::JsCast;
use web_sys::{AudioContext, AnalyserNode, HtmlElement, HtmlAudioElement, SvgElement, SvgRectElement, Window, Document};
use std::rc::Rc;
use std::cell::RefCell;
use std::sync::atomic::{AtomicBool, Ordering};
use lazy_static::lazy_static;

//constants spectrograms
const MEL_BINS: usize = 128;
const LOG_BINS: usize = 128;
const MIN_BAR_HEIGHT: u16 = 2;       // Minimum height for non-zero values
const FOCUS_FREQUENCY_RANGE: bool = true;  // Focus bins on useful frequency range
const USE_SMOOTHING: bool = true;    // Apply smoothing between bins
const USE_SPLINE_INTERPOLATION: bool = true;
const INTERPOLATION_FACTOR: usize = 4;  // Higher = smoother curve
const LOG_SPEC_GAP_FILL: bool = true;  // Special gap filling for log spectrogram
const LOG_SPEC_GAP_THRESHOLD: u8 = 10; // Minimum value to trigger gap fill
const LOG_SPEC_GAP_RADIUS: usize = 2;  // Number of neighbors to fill
const LOG_SPEC_GAP_FILL_FACTOR: f32 = 0.5; // Factor for gap fill
const LOG_SPEC_MIN_VALUE: u8 = 10;    // Minimum value for log spectrogram
const LOG_SPEC_MAX_VALUE: u8 = 255;   // Maximum value for log spectrogram
const USE_A_WEIGHTING: bool = true;  // Apply perceptual weighting to match human hearing
const NOISE_GATE_THRESHOLD: f32 = 5.0; // Threshold for noise gate (0-255)
const LOW_FREQ_ATTENUATION: f32 = 0.4; // Stronger attenuation for lowest frequencies
const HIGH_FREQ_ATTENUATION: f32 = 0.8; // Less attenuation for higher frequencies
const SMOOTHING_FACTOR: f32 = 0.6;    // Strength of the exponential smoothing
const SMOOTHING_ITERATIONS: usize = 3; // Number of smoothing iterations
const SMOOTHING_PASSES: usize = 3;     // Number of smoothing passes
const SMOOTHING_RADIUS: usize = 2;     // Radius of the smoothing filter
const SMOOTHING_FACTOR_DB: f32 = 0.5;  // Strength of the dB smoothing
const SMOOTHING_ITERATIONS_DB: usize = 2; // Number of dB smoothing iterations
const SMOOTHING_PASSES_DB: usize = 2;  // Number of dB smoothing passes
const SMOOTHING_RADIUS_DB: usize = 2;  // Radius of the dB smoothing filter
const SPLINE_TENSION: f32 = 0.5;       // Tension of the cubic spline interpolation
const SPLINE_ITERATIONS: usize = 3;    // Number of spline smoothing iterations
const SPLINE_PASSES: usize = 3;        // Number of spline smoothing passes
const SPLINE_RADIUS: usize = 2;        // Radius of the spline filter
const SPLINE_TENSION_DB: f32 = 0.5;    // Tension of the dB spline interpolation
const SPLINE_ITERATIONS_DB: usize = 2; // Number of dB spline smoothing iterations
const SPLINE_PASSES_DB: usize = 2;     // Number of dB spline smoothing passes
const SPLINE_RADIUS_DB: usize = 2;     // Radius of the dB spline filter


lazy_static! {
    static ref DEBUG: AtomicBool = AtomicBool::new(false);
    static ref PREVENT_SVG_UPDATE: AtomicBool = AtomicBool::new(false);
    static ref USE_LOG_SPECTROGRAM: AtomicBool = AtomicBool::new(false); // Add this line
}

// Add this new function to toggle between spectrograms
#[wasm_bindgen]
pub fn set_use_log_spectrogram(value: bool) {
    USE_LOG_SPECTROGRAM.store(value, Ordering::SeqCst);
}

// Define thread-local storage at the module level
thread_local! {
    static AUDIO_CONTEXT: RefCell<Option<AudioContext>> = RefCell::new(None);
    static ANALYSER: RefCell<Option<AnalyserNode>> = RefCell::new(None);
}

#[wasm_bindgen]
pub fn set_debug(value: bool) {
    DEBUG.store(value, Ordering::SeqCst);
}

#[wasm_bindgen]
pub fn set_prevent_svg_update(value: bool) {
    PREVENT_SVG_UPDATE.store(value, Ordering::SeqCst);
}

#[wasm_bindgen]
pub fn get_audio_context() -> Option<AudioContext> {
    // Return the current audio context if it exists
    AUDIO_CONTEXT.with(|ctx| ctx.borrow().clone())
}

#[wasm_bindgen]
pub fn get_analyser() -> Option<AnalyserNode> {
    // Return the current analyser if it exists
    ANALYSER.with(|a| a.borrow().clone())
}

#[wasm_bindgen(start)]
pub fn start() -> Result<(), JsValue> {
    // Set up console error handling for better debugging
    #[cfg(feature = "console_error_panic_hook")]
    console_error_panic_hook::set_once();
    
    let window = web_sys::window().expect("no global `window` exists");
    let document = window.document().expect("should have a document on window");
    
    // Use the container instead of body
    let container = document.get_element_by_id("container")
        .ok_or_else(|| JsValue::from_str("Could not find container element"))?;
    let container_elem = container.dyn_into::<HtmlElement>()?;

    let audio = create_audio_element(&document, &container_elem)?;
    let svg = create_svg_element(&document, &container_elem)?;
    
    let (audio_context, analyser, buffer_length, sample_rate, fft_size) = 
        setup_audio_processing(&audio)?;
    
    setup_playback_handler(&audio, &audio_context)?;
    
    setup_visualization_loop(
        window, 
        document, 
        svg, 
        analyser, 
        buffer_length, 
        sample_rate, 
        fft_size
    )?;
    
    Ok(())
}

fn create_audio_element(document: &Document, body: &HtmlElement) -> Result<HtmlAudioElement, JsValue> {
    let audio = document.create_element("audio")?.dyn_into::<HtmlAudioElement>()?;
    audio.set_src("./audio.mp3");
    audio.set_controls(true);
    body.append_child(&audio)?;
    Ok(audio)
}

fn create_svg_element(document: &Document, body: &HtmlElement) -> Result<SvgElement, JsValue> {
    let svg = document.create_element_ns(Some("http://www.w3.org/2000/svg"), "svg")?.dyn_into::<SvgElement>()?;
    svg.set_attribute("width", "100%")?;
    svg.set_attribute("height", "400")?;
    svg.set_attribute("viewBox", "0 0 800 400")?;
    body.append_child(&svg)?;
    Ok(svg)
}


// Store the objects in thread_local storage
fn setup_audio_processing(audio: &HtmlAudioElement) 
    -> Result<(AudioContext, AnalyserNode, u32, f32, f32), JsValue> {
    let audio_context = AudioContext::new()?;
    let analyser = audio_context.create_analyser()?;
    analyser.set_smoothing_time_constant(0.85);
    analyser.set_fft_size(256);
    let buffer_length = analyser.frequency_bin_count();
    let sample_rate = audio_context.sample_rate();
    let fft_size = analyser.fft_size() as f32;
   
    // Store for later access - use the module-level thread_local storage
    AUDIO_CONTEXT.with(|ctx| *ctx.borrow_mut() = Some(audio_context.clone()));
    ANALYSER.with(|a| *a.borrow_mut() = Some(analyser.clone()));

    let source = audio_context.create_media_element_source(audio)?;
    source.connect_with_audio_node(&analyser)?;
    analyser.connect_with_audio_node(&audio_context.destination())?;

    Ok((audio_context, analyser, buffer_length, sample_rate, fft_size))
}

fn setup_playback_handler(audio: &HtmlAudioElement, audio_context: &AudioContext) -> Result<(), JsValue> {
    let audio_context_clone = audio_context.clone();
    let closure = Closure::wrap(Box::new(move || {
        let _ = audio_context_clone.resume();
    }) as Box<dyn FnMut()>);
    audio.set_onplay(Some(closure.as_ref().unchecked_ref()));
    closure.forget(); // Avoid lifetime issues by leaking the closure
    Ok(())
}

fn create_svg_rects(document: &Document, svg: &SvgElement, count: u32) -> Result<Vec<SvgRectElement>, JsValue> {
    // First, add a style element to the SVG for more efficient styling
    let style = document.create_element_ns(Some("http://www.w3.org/2000/svg"), "style")?;
    style.set_text_content(Some(r#"
        rect {
            fill: #4a8eff;
            transition: height 0.05s ease;
        }
        rect.active {
            fill: #5a9eff;
        }
    "#));
    svg.append_child(&style)?;
    
    let mut rects = Vec::with_capacity(count as usize);
    // Use underscore to indicate intentional unused variable
    for _ in 0..count {
        let rect = document.create_element_ns(Some("http://www.w3.org/2000/svg"), "rect")?
            .dyn_into::<SvgRectElement>()?;
            
        // Set initial attributes
        rect.set_attribute("y", "400")?; // Start at bottom (height 0)
        rect.set_attribute("height", "0")?;
        
        svg.append_child(&rect)?;
        rects.push(rect);
    }
    Ok(rects)
}


fn setup_visualization_loop(
    window: Window,
    document: Document,
    svg: SvgElement,
    analyser: AnalyserNode,
    buffer_length: u32,
    sample_rate: f32,
    fft_size: f32
) -> Result<(), JsValue> {
    // Use the max of MEL_BINS and LOG_BINS since we might switch between them
    let num_bins = MEL_BINS.max(LOG_BINS);
    let rects: Vec<SvgRectElement> = create_svg_rects(&document, &svg, num_bins as u32)?;
    
    let draw: Rc<RefCell<Option<Closure<dyn FnMut()>>>> = Rc::new(RefCell::new(None));
    let draw_clone = draw.clone();
    
    // Pre-allocate these buffers to avoid frequent allocations
    let data_array = Rc::new(RefCell::new(vec![0u8; buffer_length as usize]));
    let processed_data = Rc::new(RefCell::new(vec![0u8; num_bins]));
    let data_array_clone = data_array.clone();
    let processed_data_clone = processed_data.clone();

    // Add throttling to avoid excessive updates
    let update_interval_ms = 25; // ~40 fps instead of unrestricted
    let mut last_update = js_sys::Date::now();
    
    // Clone window before moving it into the closure
    let window_for_closure = window.clone();
    
    *draw_clone.borrow_mut() = Some(Closure::wrap(Box::new(move || {
        // Extract frequency data
        let mut data = data_array_clone.borrow_mut();
        analyser.get_byte_frequency_data(&mut data);

        // Throttle updates to improve performance
        let current_time = js_sys::Date::now();
        if current_time - last_update >= update_interval_ms as f64 && 
           !PREVENT_SVG_UPDATE.load(Ordering::SeqCst) {
            
            // Process and update visualization
            let mut processed = processed_data_clone.borrow_mut();
            process_audio_data(&data, &mut processed, sample_rate, fft_size);
            update_visualization(&rects, &processed, num_bins as u32, sample_rate, fft_size);
            
            last_update = current_time;
        }

        // Schedule next frame
        window_for_closure.request_animation_frame(
            draw.borrow().as_ref().unwrap().as_ref().unchecked_ref()
        ).ok();
    }) as Box<dyn FnMut()>));

    // Start the animation loop
    window.request_animation_frame(draw_clone.borrow().as_ref().unwrap().as_ref().unchecked_ref())?;
    std::mem::forget(draw_clone);
    
    Ok(())
}

fn update_visualization(
    rects: &[SvgRectElement], 
    data_array: &[u8],
    num_bins: u32,
    sample_rate: f32,
    fft_size: f32
) {
    let bar_width = 800.0 / num_bins as f64;
    let mut x = 0.0;

    // Choose which spectrogram to use
    let mut raw_spectrogram_data = if USE_LOG_SPECTROGRAM.load(Ordering::SeqCst) {
        convert_to_log_spectrogram(data_array, sample_rate, fft_size)
    } else {
        convert_to_mel_spectrogram(data_array, sample_rate, fft_size)
    };
    
    // Apply smoothing only if enabled
    if USE_SMOOTHING {
        raw_spectrogram_data = apply_smoothing(&raw_spectrogram_data);
    }

    // Apply normalization
    let spectrogram_data = normalize_spectrogram(&raw_spectrogram_data);
    
    // Find the actual max value for scaling (avoid division by zero)
    let max_value = spectrogram_data.iter()
        .fold(1u8, |max, &val| max.max(val)) as f64;
    
    // Update each rectangle
    for (i, &value) in spectrogram_data.iter().enumerate() {
        if i >= rects.len() {
            break;
        }
        
        let value_f = value as f64;
        
        // Apply minimum height for any non-zero value
        let bar_height = if value > 0 {
            ((value_f / max_value) * 400.0) as u16
        } else {
            0
        }.max(if value > 0 { MIN_BAR_HEIGHT } else { 0 });
        
        let rect = &rects[i];
        
        // Change color intensity based on relative energy
        // This makes the visualization more informative
        let intensity = (value_f / max_value) * 100.0;
        let color = if intensity > 80.0 {
            // High intensity - bright blue
            "#4a8eff" 
        } else if intensity > 50.0 {
            // Medium intensity - medium blue
            "#3a7eef"
        } else if intensity > 20.0 {
            // Lower intensity - darker blue
            "#2a6edf"
        } else {
            // Very low intensity - darkest blue
            "#1a5ecf"
        };
        
        // Only add the "active" class if there's significant energy
        if value > 3 {
            rect.set_attribute("class", "active").ok();
        } else {
            rect.set_attribute("class", "").ok();
        }
        
        // Set the fill color directly for more visual information
        rect.set_attribute("fill", color).ok();
        
        // Update position and dimensions
        rect.set_attribute("x", &x.to_string()).ok();
        rect.set_attribute("y", &(400 - bar_height).to_string()).ok();
        rect.set_attribute("height", &bar_height.to_string()).ok();
        rect.set_attribute("width", &(bar_width * 0.9).to_string()).ok();
        
        x += bar_width;
    }
}

fn convert_to_mel_spectrogram(data_array: &[u8], sample_rate: f32, fft_size: f32) -> Vec<u8> {
    // Pre-compute mel filter bank only once per sample rate
    // This can be cached with thread_local! if the sample rate doesn't change
    thread_local! {
        static MEL_FILTER_BANK: RefCell<Option<(f32, Vec<(Vec<usize>, Vec<f32>)>)>> = RefCell::new(None);
    }
    
    let num_mel_bins = MEL_BINS;
    let mut mel_data = vec![0.0_f32; num_mel_bins];
    
    // Check if we need to recompute the filter bank
    let filter_bank = MEL_FILTER_BANK.with(|filter_bank_cell| {
        let mut filter_bank = filter_bank_cell.borrow_mut();
        
        if filter_bank.is_none() || filter_bank.as_ref().unwrap().0 != sample_rate {
            // Pre-compute mel filter banks
            let min_freq: f32 = 20.0;
            let max_freq: f32 = sample_rate / 2.0;
            
            let min_mel = 2595.0 * (1.0 + min_freq / 700.0).log10();
            let max_mel = 2595.0 * (1.0 + max_freq / 700.0).log10();
            
            let mut filter_indexes = Vec::with_capacity(num_mel_bins);
            let mut filter_weights = Vec::with_capacity(num_mel_bins);
            
            let fft_bin_count = data_array.len();
            
            // For each mel bin, pre-compute which FFT bins contribute to it
            for j in 0..num_mel_bins {
                let mel_low = min_mel + (max_mel - min_mel) * (j as f32 / (num_mel_bins + 1) as f32);
                let mel_center = min_mel + (max_mel - min_mel) * ((j + 1) as f32 / (num_mel_bins + 1) as f32);
                let mel_high = min_mel + (max_mel - min_mel) * ((j + 2) as f32 / (num_mel_bins + 1) as f32);
                
                let hz_low = 700.0 * (10.0_f32.powf(mel_low / 2595.0) - 1.0);
                let hz_center = 700.0 * (10.0_f32.powf(mel_center / 2595.0) - 1.0);
                let hz_high = 700.0 * (10.0_f32.powf(mel_high / 2595.0) - 1.0);
                
                let mut bin_indexes = Vec::new();
                let mut weights = Vec::new();
                
                // Find which FFT bins contribute to this mel bin
                for i in 0..fft_bin_count {
                    let freq_hz = i as f32 * sample_rate / fft_size;
                    
                    if freq_hz >= hz_low && freq_hz <= hz_high {
                        let weight = if freq_hz <= hz_center {
                            (freq_hz - hz_low) / (hz_center - hz_low)
                        } else {
                            (hz_high - freq_hz) / (hz_high - hz_center)
                        };
                        
                        if weight > 0.01 { // Ignore negligible weights
                            bin_indexes.push(i);
                            weights.push(weight);
                        }
                    }
                }
                
                filter_indexes.push(bin_indexes);
                filter_weights.push(weights);
            }
            
            // Create a combined data structure
            let combined_filters: Vec<(Vec<usize>, Vec<f32>)> = 
                filter_indexes.into_iter()
                .zip(filter_weights.into_iter())
                .collect();

            // Assign the correctly structured data to filter_bank
            *filter_bank = Some((sample_rate, combined_filters));
        }
        
        filter_bank.clone().unwrap()
    });
    
    // Get the combined filters vector
    let (_, combined_filters) = filter_bank;

    // Then use them in your processing loop
    for j in 0..num_mel_bins {
        let mut energy = 0.0;
        let mut count = 0;
        
        // Access the tuple for this mel bin
        let (bin_indexes, weights) = &combined_filters[j];
        
        // Process using these values
        for k in 0..bin_indexes.len() {
            let i = bin_indexes[k];
            let value = data_array[i];
            
            if value > NOISE_GATE_THRESHOLD as u8 {
                energy += value as f32 * weights[k];
                count += 1;
            }
        }
        
        // Store the result in mel_data
        if count > 0 {
            mel_data[j] = energy / count as f32;
        }
    }
    
    // Apply frequency-dependent processing
    for i in 0..num_mel_bins {
        // Get the base value
        let mut value = mel_data[i];
        
        // Apply A-weighting
        if USE_A_WEIGHTING {
            // Calculate the center frequency for this specific bin
            let min_freq: f32 = 20.0;
            let max_freq: f32 = sample_rate / 2.0;
            let min_mel = 2595.0 * (1.0 + min_freq / 700.0).log10();
            let max_mel = 2595.0 * (1.0 + max_freq / 700.0).log10();
            
            // Calculate the mel value for this bin
            let mel = min_mel + (max_mel - min_mel) * ((i + 1) as f32 / (num_mel_bins + 1) as f32);
            
            // Convert mel to Hz
            let center_freq = 700.0 * (10.0_f32.powf(mel / 2595.0) - 1.0);
            
            // Simplified A-weighting for performance
            let f2 = center_freq * center_freq;
            let ra = (f2 + 20.6_f32.powi(2)) * 
                   ((f2 + 107.7_f32.powi(2)) * (f2 + 737.9_f32.powi(2))).sqrt() * 
                   (f2 + 12194.0_f32.powi(2));
            
            let weight = ((12194.0_f32.powi(2) * f2 * f2) / ra).max(0.05);
            value *= weight;
        }
        
        // Apply low/high frequency attenuation
        if i < num_mel_bins / 8 {
            value *= LOW_FREQ_ATTENUATION + 
                    (1.0 - LOW_FREQ_ATTENUATION) * (i as f32 / (num_mel_bins / 8) as f32);
        } else if i > num_mel_bins * 3/4 {
            let position = (i - (num_mel_bins * 3/4)) as f32 / (num_mel_bins / 4) as f32;
            value *= 1.0 - (1.0 - HIGH_FREQ_ATTENUATION) * position;
        }
        
        mel_data[i] = value.clamp(0.0, 255.0);
    }
    
    // Apply spline interpolation if enabled (but use the optimized version)
    if USE_SPLINE_INTERPOLATION {
        mel_data = apply_cubic_spline_interpolation(&mel_data);
    }
    
    // Convert to bytes
    mel_data.iter().map(|&v| v as u8).collect()
}


/// Converts linear frequency data to logarithmic bins for better psychoacoustic representation.
/// 
/// Human hearing perception is roughly logarithmic - we perceive the difference between
/// 100Hz and 200Hz as approximately the same as the difference between 1000Hz and 2000Hz,
/// even though the actual frequency difference is much larger in the second case.
/// 
/// This function remaps the linear FFT data to logarithmically spaced frequency bins,
/// which better represents how we actually perceive sound.
/// 
/// # Parameters
/// * `data_array` - The raw frequency data from the FFT (linear bins)
/// * `sample_rate` - Sample rate of the audio in Hz
/// * `fft_size` - Size of the FFT window
/// 
/// # Returns
/// A vector of amplitude values in logarithmically spaced frequency bins
fn convert_to_log_spectrogram(data_array: &[u8], sample_rate: f32, fft_size: f32) -> Vec<u8> {
    let num_log_bins: usize = LOG_BINS;
    let min_freq: f32 = 20.0;  // Lower limit of human hearing
    let max_freq: f32 = if FOCUS_FREQUENCY_RANGE {
        (10000.0_f32).min(sample_rate / 2.0)
    } else {
        sample_rate / 2.0
    };
    
    // Use true logarithmic spacing with expanded bin coverage
    let min_log = min_freq.ln();
    let max_log = max_freq.ln();
    let log_step = (max_log - min_log) / (num_log_bins as f32);
    
    // Generate logarithmically spaced frequency points with overlap
    let mut log_freq_points = Vec::with_capacity(num_log_bins + 1);
    for i in 0..=num_log_bins {
        log_freq_points.push((min_log + i as f32 * log_step).exp());
    }
    
    // Initialize arrays for energy accumulation
    let mut log_energies = vec![0.0_f32; num_log_bins];
    let mut bin_counts = vec![0_u32; num_log_bins];
    
    // Calculate energy per bin with proper weighting
    for (i, &value) in data_array.iter().enumerate() {
        if value == 0 { continue; }
        
        let freq_hz = (i as f32 + 0.5) * sample_rate / fft_size;
        if freq_hz < min_freq || freq_hz > max_freq { continue; }
        
        // Find relevant bins with expanded coverage for better continuity
        for j in 0..num_log_bins {
            let lower = if j > 0 { log_freq_points[j-1] } else { min_freq };
            let upper = log_freq_points[j.min(num_log_bins-1)+1];
            
            // Expand bin coverage to create overlap between adjacent bins
            let bin_width = upper - lower;
            let expanded_lower = lower - bin_width * 0.2;
            let expanded_upper = upper + bin_width * 0.2;
            
            if freq_hz >= expanded_lower && freq_hz <= expanded_upper {
                // Calculate weight using a proper window function
                let center = (lower + upper) / 2.0;
                let normalized_distance = (freq_hz - center) / bin_width;
                
                // Apply modified Hann window for weighting
                let weight = 0.5 * (1.0 - (normalized_distance * 2.0).cos()) *
                             (1.0 - normalized_distance.abs() * 1.5).max(0.0);
                
                if weight > 0.0 {
                    log_energies[j] += value as f32 * weight;
                    bin_counts[j] += 1;
                }
            }
        }
    }
    
    // Process the energies into visualization data
    let mut log_data = vec![0.0_f32; num_log_bins];
    
    // Calculate values using industry-standard techniques
    for i in 0..num_log_bins {
        // Convert energy to proper value
        let mut value = if bin_counts[i] > 0 {
            log_energies[i] / bin_counts[i] as f32
        } else {
            0.0
        };
        
        // Apply minimum floor from constant
        if value > 0.0 {
            value = value.max(LOG_SPEC_MIN_VALUE as f32);
        }
        
        // Apply frequency-dependent boost
        let freq_position = i as f32 / num_log_bins as f32;
        let boost_factor = if freq_position < 0.3 {
            1.2  // Low frequencies
        } else if freq_position < 0.7 {
            1.1  // Mid frequencies
        } else {
            1.0 + freq_position * 0.3  // High frequencies
        };
        
        // Apply boost and clamp to max value
        value = (value * boost_factor).clamp(0.0, LOG_SPEC_MAX_VALUE as f32);
        log_data[i] = value;
    }
    
    // Apply gap filling if enabled
    if LOG_SPEC_GAP_FILL {
        log_data = fill_log_spectrogram_gaps(&log_data);
    }
    
    // Apply spline interpolation for smoothness
    if USE_SPLINE_INTERPOLATION {
        log_data = apply_cubic_spline_interpolation(&log_data);
    }
    
    // Convert to bytes
    log_data.iter().map(|&v| v as u8).collect()
}


/// Apply industry-standard normalization to spectrogram data
/// 
/// This function applies several professional audio normalization techniques:
/// 1. dB scaling (logarithmic amplitude which better matches human perception)
/// 2. Noise floor thresholding 
/// 3. Dynamic range compression
/// 4. Visualization scaling
fn apply_smoothing(data: &[u8]) -> Vec<u8> {
    let mut smoothed = vec![0; data.len()];
    
    // First convert to floating point for more precise operations
    let mut data_f32: Vec<f32> = data.iter().map(|&x| x as f32).collect();
    
    // Apply multi-pass smoothing in linear domain
    for _ in 0..SMOOTHING_PASSES {
        // Multiple iterations with adjustable radius
        for _ in 0..SMOOTHING_ITERATIONS {
            let prev_data = data_f32.clone();
            
            for i in 0..data_f32.len() {
                // Base center weight
                let center_weight = 1.0 - SMOOTHING_FACTOR;
                let mut sum = prev_data[i] * center_weight;
                let mut total_weight = center_weight;
                
                // Apply variable radius smoothing
                for radius in 1..=SMOOTHING_RADIUS {
                    // Calculate weight based on distance (closer = higher weight)
                    let radius_weight = SMOOTHING_FACTOR * (1.0 - (radius as f32 / (SMOOTHING_RADIUS + 1) as f32));
                    
                    // Apply different weights based on frequency position
                    let freq_position = i as f32 / data_f32.len() as f32;
                    let freq_factor = if freq_position < 0.2 {
                        // More aggressive smoothing for low frequencies
                        1.2
                    } else if freq_position > 0.8 {
                        // Less aggressive for highest frequencies (maintain detail)
                        0.8 * HIGH_FREQ_ATTENUATION
                    } else {
                        // Standard for mid-range
                        1.0
                    };
                    
                    let effective_weight = radius_weight * freq_factor;
                    
                    // Apply to both sides if within bounds
                    // Fixed syntax issue with proper parentheses
                    for offset in &[-(radius as isize), radius as isize] {
                        let pos = i as isize + offset;
                        if pos >= 0 && pos < data_f32.len() as isize {
                            sum += prev_data[pos as usize] * effective_weight;
                            total_weight += effective_weight;
                        }
                    }
                }
                
                // Calculate smoothed value
                if total_weight > 0.0 {
                    data_f32[i] = sum / total_weight;
                }
            }
        }
    }
    
    // Apply dB domain smoothing for psychoacoustic correctness
    if SMOOTHING_PASSES_DB > 0 {
        // Convert to dB for perceptual smoothing
        let mut db_data: Vec<f32> = data_f32.iter().map(|&x| {
            if x > 1.0 {
                20.0 * x.log10()
            } else {
                -60.0 // dB floor for zero/near-zero values
            }
        }).collect();
        
        // Apply multi-pass dB-domain smoothing
        for _ in 0..SMOOTHING_PASSES_DB {
            for _ in 0..SMOOTHING_ITERATIONS_DB {
                let prev_db = db_data.clone();
                
                for i in 0..db_data.len() {
                    let center_weight = 1.0 - SMOOTHING_FACTOR_DB;
                    let mut sum = prev_db[i] * center_weight;
                    let mut total_weight = center_weight;
                    
                    // Apply smoothing with variable radius
                    for radius in 1..=SMOOTHING_RADIUS_DB {
                        let radius_weight = SMOOTHING_FACTOR_DB * 
                            (1.0 - (radius as f32 / (SMOOTHING_RADIUS_DB + 1) as f32));
                        
                        // Apply to both sides if within bounds
                        // Fixed syntax issue with proper parentheses
                        for offset in &[-(radius as isize), radius as isize] {
                            let pos = i as isize + offset;
                            if pos >= 0 && pos < db_data.len() as isize {
                                sum += prev_db[pos as usize] * radius_weight;
                                total_weight += radius_weight;
                            }
                        }
                    }
                    
                    // Calculate smoothed dB value
                    if total_weight > 0.0 {
                        db_data[i] = sum / total_weight;
                    }
                }
            }
        }
        
        // Convert back to linear
        for i in 0..data_f32.len() {
            data_f32[i] = 10.0_f32.powf(db_data[i] / 20.0);
        }
    }
    
    // Apply frequency-dependent fill-in for lower frequencies
    let low_freq_range = data_f32.len() / 5;  // Just focus on the lowest 20%
    for i in 1..low_freq_range-1 {
        let avg_neighbors = (data_f32[i-1] + data_f32[i+1]) * 0.5;
        // If this point is significantly lower than its neighbors
        if data_f32[i] < avg_neighbors * 0.6 {
            // Fill the valley with at least 40% of the average of neighbors
            data_f32[i] = data_f32[i].max(avg_neighbors * 0.4);
        }
    }
    
    // Convert back to u8
    for i in 0..data_f32.len() {
        smoothed[i] = data_f32[i].clamp(0.0, 255.0) as u8;
    }
    
    smoothed
}

/// Apply cubic spline interpolation to create a smooth continuous curve
fn apply_cubic_spline_interpolation(data: &[f32]) -> Vec<f32> {
    let original_len = data.len();
    let high_res_len = original_len * INTERPOLATION_FACTOR;
    
    let mut interpolated = vec![0.0; high_res_len];
    
    // Pre-compute derivatives once
    let mut derivatives = vec![0.0; original_len];
    
    // Interior points
    for i in 1..original_len-1 {
        derivatives[i] = (data[i+1] - data[i-1]) / 2.0 * (1.0 - SPLINE_TENSION);
    }
    
    // Endpoints
    if original_len > 1 {
        derivatives[0] = (data[1] - data[0]) * (1.0 - SPLINE_TENSION);
        derivatives[original_len-1] = (data[original_len-1] - data[original_len-2]) * (1.0 - SPLINE_TENSION);
    }
    
    // Initial interpolation
    for i in 0..high_res_len {
        let t = i as f32 / high_res_len as f32 * original_len as f32;
        let index = t.floor() as usize;
        let index = index.min(original_len - 2).max(0);
        
        let local_t = t - index as f32;
        
        // Hermite interpolation
        let p0 = data[index];
        let p1 = data[index + 1];
        let m0 = derivatives[index];
        let m1 = derivatives[index + 1];
        
        let h00 = 2.0 * local_t.powi(3) - 3.0 * local_t.powi(2) + 1.0;
        let h10 = local_t.powi(3) - 2.0 * local_t.powi(2) + local_t;
        let h01 = -2.0 * local_t.powi(3) + 3.0 * local_t.powi(2);
        let h11 = local_t.powi(3) - local_t.powi(2);
        
        interpolated[i] = h00 * p0 + h10 * m0 + h01 * p1 + h11 * m1;
    }
    
    // Apply smoothing passes efficiently
    for _ in 0..SPLINE_PASSES {
        for _ in 0..SPLINE_ITERATIONS {
            let prev_data = interpolated.clone(); // Single clone per iteration
            
            for i in 0..high_res_len {
                let center_weight = 1.0 - (SPLINE_TENSION * 0.5);
                let mut sum = prev_data[i] * center_weight;
                let mut total_weight = center_weight;
                
                for radius in 1..=SPLINE_RADIUS {
                    let radius_weight = (SPLINE_TENSION * 0.5) * 
                        (1.0 - (radius as f32 / (SPLINE_RADIUS + 1) as f32));
                    
                    for offset in &[-(radius as isize), radius as isize] {
                        let pos = i as isize + offset;
                        if pos >= 0 && pos < high_res_len as isize {
                            sum += prev_data[pos as usize] * radius_weight;
                            total_weight += radius_weight;
                        }
                    }
                }
                
                interpolated[i] = sum / total_weight;
            }
        }
    }
    
    // Handle DB processing separately, not within the main loop
    if SPLINE_PASSES_DB > 0 {
        // Process in dB domain for final result
        let mut db_data = interpolated.iter().map(|&x| {
            if x > 1.0 { 20.0 * x.log10() } else { -60.0 }
        }).collect::<Vec<f32>>();
        
        // Apply dB domain smoothing
        for _ in 0..SPLINE_PASSES_DB {
            for _ in 0..SPLINE_ITERATIONS_DB {
                let prev_db = db_data.clone();
                
                for i in 0..high_res_len {
                    // Similar smoothing logic but for dB values
                    let center_weight = 1.0 - SPLINE_TENSION_DB;
                    let mut sum = prev_db[i] * center_weight;
                    let mut total_weight = center_weight;
                    
                    for radius in 1..=SPLINE_RADIUS_DB {
                        let radius_weight = SPLINE_TENSION_DB * 
                            (1.0 - (radius as f32 / (SPLINE_RADIUS_DB + 1) as f32));
                        
                        for offset in &[-(radius as isize), radius as isize] {
                            let pos = i as isize + offset;
                            if pos >= 0 && pos < high_res_len as isize {
                                sum += prev_db[pos as usize] * radius_weight;
                                total_weight += radius_weight;
                            }
                        }
                    }
                    
                    db_data[i] = sum / total_weight;
                }
            }
        }
        
        // Convert back to linear domain
        for i in 0..high_res_len {
            interpolated[i] = 10.0_f32.powf(db_data[i] / 20.0);
        }
    }
    
    // Downsample to original resolution
    let mut result = vec![0.0; original_len];
    let step = high_res_len as f32 / original_len as f32;
    
    for i in 0..original_len {
        let exact_pos = i as f32 * step;
        let pos_floor = exact_pos.floor() as usize;
        let pos_ceil = (pos_floor + 1).min(high_res_len - 1);
        let t = exact_pos - pos_floor as f32;
        
        result[i] = interpolated[pos_floor] * (1.0 - t) + interpolated[pos_ceil] * t;
    }
    
    result
}

// Special function to specifically address gaps in log spectrogram
fn fill_log_spectrogram_gaps(data: &[f32]) -> Vec<f32> {
    let mut filled = data.to_vec();
    let len = data.len();
    
    // Define thresholds using constants instead of hardcoded values
    let activity_threshold = LOG_SPEC_GAP_THRESHOLD as f32; // Use constant for activity detection
    let significant_value = LOG_SPEC_GAP_THRESHOLD as f32 * 2.0; // Higher threshold for significant peaks
    let minimal_value = LOG_SPEC_MIN_VALUE as f32 * 0.5; // Minimum floor for all bins
    let max_gap_size = 15; // Maximum gap size to fill (could be made into a constant)
    
    // First pass: identify "islands" of activity and gaps between them
    let mut islands: Vec<(usize, usize)> = Vec::new();
    let mut start = None;
    
    // Find regions of activity (islands)
    for i in 0..len {
        if data[i] > activity_threshold && start.is_none() {
            // Start of a new island
            start = Some(i);
        } else if data[i] <= activity_threshold && start.is_some() {
            // End of an island
            islands.push((start.unwrap(), i - 1));
            start = None;
        }
    }
    
    // Don't forget the last island if it extends to the end
    if let Some(s) = start {
        islands.push((s, len - 1));
    }
    
    // Second pass: fill in gaps between islands using standardized gap filling factor
    for i in 0..islands.len().saturating_sub(1) {
        let (_, end_first) = islands[i];
        let (start_second, _) = islands[i + 1];
        
        let gap_size = start_second - end_first - 1;
        
        // Only fill relatively small gaps
        if gap_size > 0 && gap_size < max_gap_size {
            // Use linear interpolation to fill the gap
            let left_value = data[end_first];
            let right_value = data[start_second];
            
            for j in 1..=gap_size {
                let pos = end_first + j;
                let t = j as f32 / (gap_size + 1) as f32;
                
                // Linear interpolation with industry-standard scaling factor
                let interp_value = left_value * (1.0 - t) + right_value * t;
                filled[pos] = interp_value * LOG_SPEC_GAP_FILL_FACTOR;
            }
        }
    }
    
    // Third pass: ensure minimum values around active bins within radius
    for i in LOG_SPEC_GAP_RADIUS..len.saturating_sub(LOG_SPEC_GAP_RADIUS) {
        if filled[i] > significant_value {
            // Apply to neighbors within defined radius
            for offset in 1..=LOG_SPEC_GAP_RADIUS as isize {
                // Process neighbors on both sides
                for j in [i as isize - offset, i as isize + offset] {
                    if j >= 0 && j < len as isize {
                        let j_idx = j as usize;
                        // Only modify if current value is below minimal threshold
                        if filled[j_idx] < minimal_value {
                            // Scale based on distance from center (farther = less influence)
                            let distance_factor = 1.0 - (offset as f32 / (LOG_SPEC_GAP_RADIUS + 1) as f32);
                            let min_neighbor_value = filled[i] * LOG_SPEC_GAP_FILL_FACTOR * distance_factor;
                            filled[j_idx] = filled[j_idx].max(min_neighbor_value);
                        }
                    }
                }
            }
        }
    }
    
    // Apply minimum floor across entire spectrum to avoid complete silence
    for i in 0..len {
        if filled[i] < LOG_SPEC_MIN_VALUE as f32 * 0.1 {
            // Use a small fraction of minimum value as absolute floor
            filled[i] = filled[i].max(LOG_SPEC_MIN_VALUE as f32 * 0.1);
        }
    }
    
    filled
}


/// Apply industry-standard normalization to spectrogram data
/// 
/// This function applies several professional audio normalization techniques:
/// 1. dB scaling (logarithmic amplitude which better matches human perception)
/// 2. Noise floor thresholding 
/// 3. Dynamic range compression
/// 4. Visualization scaling
fn normalize_spectrogram(raw_data: &[u8]) -> Vec<u8> {
    // Keep your existing code, but add this section at the beginning:
    
    let use_log = USE_LOG_SPECTROGRAM.load(Ordering::SeqCst);
    let mut normalized = Vec::with_capacity(raw_data.len());
    
    // Apply frequency-dependent noise gating to reduce bass dominance
    // This is an industry standard technique
    let silence_threshold = if use_log { 3 } else { 5 };
    
    // Find the max value across all bands 
    let max_value = raw_data.iter()
        .fold(1u8, |max, &val| max.max(val)) as f64;
    
    // Only apply strong processing if the overall level is low
    // (industry standard approach - only process heavily during quiet passages)
    let is_quiet_passage = max_value < 50.0;
    
    for (i, &sample) in raw_data.iter().enumerate() {
        let freq_position = i as f64 / raw_data.len() as f64;
        
        // Apply stricter thresholds to lower frequencies
        // Industry standard: bass needs higher thresholds to avoid noise dominance
        let band_threshold = if freq_position < 0.2 {
            // Low frequencies (bass) - higher threshold
            if is_quiet_passage {
                silence_threshold * 3  // Even stricter during quiet passages
            } else {
                silence_threshold * 2
            }
        } else if freq_position < 0.4 {
            // Low-mid frequencies - moderate threshold
            silence_threshold + 1
        } else {
            // Mid and high frequencies - standard threshold
            silence_threshold
        };
        
        // Apply the threshold
        let gated_value = if sample <= band_threshold {
            0
        } else {
            sample
        };
        
        // Continue with your existing normalization pipeline using gated_value
        
        // For now, just use this value (replace with your full processing)
        normalized.push(gated_value);
    }
    
    // Rest of your normalization code follows...
    normalized
}

fn process_audio_data(data: &[u8], output: &mut [u8], sample_rate: f32, fft_size: f32) {
    // Choose which spectrogram to use
    let raw_data = if USE_LOG_SPECTROGRAM.load(Ordering::SeqCst) {
        convert_to_log_spectrogram(data, sample_rate, fft_size)
    } else {
        convert_to_mel_spectrogram(data, sample_rate, fft_size)
    };
    
    // Apply smoothing and normalization
    let processed = if USE_SMOOTHING {
        apply_smoothing(&raw_data)
    } else {
        raw_data
    };
    
    // Apply final normalization
    let result = normalize_spectrogram(&processed);
    
    // Copy to the pre-allocated output buffer
    output.copy_from_slice(&result);
}
```

## File: ../../../../../opt/caddy/html/reveal/public/wasm_spectrometer/pkg/wasm_spectrometer.js <a id="file-wasm-spectrometer-js"></a>

```javascript
const lAudioContext = (typeof AudioContext !== 'undefined' ? AudioContext : (typeof webkitAudioContext !== 'undefined' ? webkitAudioContext : undefined));
let wasm;

function addToExternrefTable0(obj) {
    const idx = wasm.__externref_table_alloc();
    wasm.__wbindgen_export_2.set(idx, obj);
    return idx;
}

function handleError(f, args) {
    try {
        return f.apply(this, args);
    } catch (e) {
        const idx = addToExternrefTable0(e);
        wasm.__wbindgen_exn_store(idx);
    }
}

const cachedTextDecoder = (typeof TextDecoder !== 'undefined' ? new TextDecoder('utf-8', { ignoreBOM: true, fatal: true }) : { decode: () => { throw Error('TextDecoder not available') } } );

if (typeof TextDecoder !== 'undefined') { cachedTextDecoder.decode(); };

let cachedUint8ArrayMemory0 = null;

function getUint8ArrayMemory0() {
    if (cachedUint8ArrayMemory0 === null || cachedUint8ArrayMemory0.byteLength === 0) {
        cachedUint8ArrayMemory0 = new Uint8Array(wasm.memory.buffer);
    }
    return cachedUint8ArrayMemory0;
}

function getStringFromWasm0(ptr, len) {
    ptr = ptr >>> 0;
    return cachedTextDecoder.decode(getUint8ArrayMemory0().subarray(ptr, ptr + len));
}

function isLikeNone(x) {
    return x === undefined || x === null;
}

function getArrayU8FromWasm0(ptr, len) {
    ptr = ptr >>> 0;
    return getUint8ArrayMemory0().subarray(ptr / 1, ptr / 1 + len);
}

let WASM_VECTOR_LEN = 0;

const cachedTextEncoder = (typeof TextEncoder !== 'undefined' ? new TextEncoder('utf-8') : { encode: () => { throw Error('TextEncoder not available') } } );

const encodeString = (typeof cachedTextEncoder.encodeInto === 'function'
    ? function (arg, view) {
    return cachedTextEncoder.encodeInto(arg, view);
}
    : function (arg, view) {
    const buf = cachedTextEncoder.encode(arg);
    view.set(buf);
    return {
        read: arg.length,
        written: buf.length
    };
});

function passStringToWasm0(arg, malloc, realloc) {

    if (realloc === undefined) {
        const buf = cachedTextEncoder.encode(arg);
        const ptr = malloc(buf.length, 1) >>> 0;
        getUint8ArrayMemory0().subarray(ptr, ptr + buf.length).set(buf);
        WASM_VECTOR_LEN = buf.length;
        return ptr;
    }

    let len = arg.length;
    let ptr = malloc(len, 1) >>> 0;

    const mem = getUint8ArrayMemory0();

    let offset = 0;

    for (; offset < len; offset++) {
        const code = arg.charCodeAt(offset);
        if (code > 0x7F) break;
        mem[ptr + offset] = code;
    }

    if (offset !== len) {
        if (offset !== 0) {
            arg = arg.slice(offset);
        }
        ptr = realloc(ptr, len, len = offset + arg.length * 3, 1) >>> 0;
        const view = getUint8ArrayMemory0().subarray(ptr + offset, ptr + len);
        const ret = encodeString(arg, view);

        offset += ret.written;
        ptr = realloc(ptr, len, offset, 1) >>> 0;
    }

    WASM_VECTOR_LEN = offset;
    return ptr;
}

let cachedDataViewMemory0 = null;

function getDataViewMemory0() {
    if (cachedDataViewMemory0 === null || cachedDataViewMemory0.buffer.detached === true || (cachedDataViewMemory0.buffer.detached === undefined && cachedDataViewMemory0.buffer !== wasm.memory.buffer)) {
        cachedDataViewMemory0 = new DataView(wasm.memory.buffer);
    }
    return cachedDataViewMemory0;
}

const CLOSURE_DTORS = (typeof FinalizationRegistry === 'undefined')
    ? { register: () => {}, unregister: () => {} }
    : new FinalizationRegistry(state => {
    wasm.__wbindgen_export_6.get(state.dtor)(state.a, state.b)
});

function makeMutClosure(arg0, arg1, dtor, f) {
    const state = { a: arg0, b: arg1, cnt: 1, dtor };
    const real = (...args) => {
        // First up with a closure we increment the internal reference
        // count. This ensures that the Rust closure environment won't
        // be deallocated while we're invoking it.
        state.cnt++;
        const a = state.a;
        state.a = 0;
        try {
            return f(a, state.b, ...args);
        } finally {
            if (--state.cnt === 0) {
                wasm.__wbindgen_export_6.get(state.dtor)(a, state.b);
                CLOSURE_DTORS.unregister(state);
            } else {
                state.a = a;
            }
        }
    };
    real.original = state;
    CLOSURE_DTORS.register(real, state, state);
    return real;
}
/**
 * @param {boolean} value
 */
export function set_use_log_spectrogram(value) {
    wasm.set_use_log_spectrogram(value);
}

/**
 * @param {boolean} value
 */
export function set_debug(value) {
    wasm.set_debug(value);
}

/**
 * @param {boolean} value
 */
export function set_prevent_svg_update(value) {
    wasm.set_prevent_svg_update(value);
}

/**
 * @returns {AudioContext | undefined}
 */
export function get_audio_context() {
    const ret = wasm.get_audio_context();
    return ret;
}

/**
 * @returns {AnalyserNode | undefined}
 */
export function get_analyser() {
    const ret = wasm.get_analyser();
    return ret;
}

export function start() {
    wasm.start();
}

function __wbg_adapter_18(arg0, arg1) {
    wasm._dyn_core__ops__function__FnMut_____Output___R_as_wasm_bindgen__closure__WasmClosure___describe__invoke__h7c5b803a84696b18(arg0, arg1);
}

async function __wbg_load(module, imports) {
    if (typeof Response === 'function' && module instanceof Response) {
        if (typeof WebAssembly.instantiateStreaming === 'function') {
            try {
                return await WebAssembly.instantiateStreaming(module, imports);

            } catch (e) {
                if (module.headers.get('Content-Type') != 'application/wasm') {
                    console.warn("`WebAssembly.instantiateStreaming` failed because your server does not serve Wasm with `application/wasm` MIME type. Falling back to `WebAssembly.instantiate` which is slower. Original error:\n", e);

                } else {
                    throw e;
                }
            }
        }

        const bytes = await module.arrayBuffer();
        return await WebAssembly.instantiate(bytes, imports);

    } else {
        const instance = await WebAssembly.instantiate(module, imports);

        if (instance instanceof WebAssembly.Instance) {
            return { instance, module };

        } else {
            return instance;
        }
    }
}

function __wbg_get_imports() {
    const imports = {};
    imports.wbg = {};
    imports.wbg.__wbg_appendChild_8204974b7328bf98 = function() { return handleError(function (arg0, arg1) {
        const ret = arg0.appendChild(arg1);
        return ret;
    }, arguments) };
    imports.wbg.__wbg_call_672a4d21634d4a24 = function() { return handleError(function (arg0, arg1) {
        const ret = arg0.call(arg1);
        return ret;
    }, arguments) };
    imports.wbg.__wbg_connect_b22945d106632a36 = function() { return handleError(function (arg0, arg1) {
        const ret = arg0.connect(arg1);
        return ret;
    }, arguments) };
    imports.wbg.__wbg_createAnalyser_6f61fea80d3f3c71 = function() { return handleError(function (arg0) {
        const ret = arg0.createAnalyser();
        return ret;
    }, arguments) };
    imports.wbg.__wbg_createElementNS_914d752e521987da = function() { return handleError(function (arg0, arg1, arg2, arg3, arg4) {
        const ret = arg0.createElementNS(arg1 === 0 ? undefined : getStringFromWasm0(arg1, arg2), getStringFromWasm0(arg3, arg4));
        return ret;
    }, arguments) };
    imports.wbg.__wbg_createElement_8c9931a732ee2fea = function() { return handleError(function (arg0, arg1, arg2) {
        const ret = arg0.createElement(getStringFromWasm0(arg1, arg2));
        return ret;
    }, arguments) };
    imports.wbg.__wbg_createMediaElementSource_a234914f1c6b1bbc = function() { return handleError(function (arg0, arg1) {
        const ret = arg0.createMediaElementSource(arg1);
        return ret;
    }, arguments) };
    imports.wbg.__wbg_destination_6400091abd6f01b3 = function(arg0) {
        const ret = arg0.destination;
        return ret;
    };
    imports.wbg.__wbg_document_d249400bd7bd996d = function(arg0) {
        const ret = arg0.document;
        return isLikeNone(ret) ? 0 : addToExternrefTable0(ret);
    };
    imports.wbg.__wbg_error_7534b8e9a36f1ab4 = function(arg0, arg1) {
        let deferred0_0;
        let deferred0_1;
        try {
            deferred0_0 = arg0;
            deferred0_1 = arg1;
            console.error(getStringFromWasm0(arg0, arg1));
        } finally {
            wasm.__wbindgen_free(deferred0_0, deferred0_1, 1);
        }
    };
    imports.wbg.__wbg_fftSize_d0123ed639f9562c = function(arg0) {
        const ret = arg0.fftSize;
        return ret;
    };
    imports.wbg.__wbg_frequencyBinCount_e1294463a975de37 = function(arg0) {
        const ret = arg0.frequencyBinCount;
        return ret;
    };
    imports.wbg.__wbg_getByteFrequencyData_c4c5b8b09c454a14 = function(arg0, arg1, arg2) {
        arg0.getByteFrequencyData(getArrayU8FromWasm0(arg1, arg2));
    };
    imports.wbg.__wbg_getElementById_f827f0d6648718a8 = function(arg0, arg1, arg2) {
        const ret = arg0.getElementById(getStringFromWasm0(arg1, arg2));
        return isLikeNone(ret) ? 0 : addToExternrefTable0(ret);
    };
    imports.wbg.__wbg_instanceof_HtmlAudioElement_3c635ee8f8b85c84 = function(arg0) {
        let result;
        try {
            result = arg0 instanceof HTMLAudioElement;
        } catch (_) {
            result = false;
        }
        const ret = result;
        return ret;
    };
    imports.wbg.__wbg_instanceof_HtmlElement_51378c201250b16c = function(arg0) {
        let result;
        try {
            result = arg0 instanceof HTMLElement;
        } catch (_) {
            result = false;
        }
        const ret = result;
        return ret;
    };
    imports.wbg.__wbg_instanceof_SvgElement_5506294bde67d463 = function(arg0) {
        let result;
        try {
            result = arg0 instanceof SVGElement;
        } catch (_) {
            result = false;
        }
        const ret = result;
        return ret;
    };
    imports.wbg.__wbg_instanceof_SvgRectElement_b52bf33f06060562 = function(arg0) {
        let result;
        try {
            result = arg0 instanceof SVGRectElement;
        } catch (_) {
            result = false;
        }
        const ret = result;
        return ret;
    };
    imports.wbg.__wbg_instanceof_Window_def73ea0955fc569 = function(arg0) {
        let result;
        try {
            result = arg0 instanceof Window;
        } catch (_) {
            result = false;
        }
        const ret = result;
        return ret;
    };
    imports.wbg.__wbg_new_4b3dfb29a594e831 = function() { return handleError(function () {
        const ret = new lAudioContext();
        return ret;
    }, arguments) };
    imports.wbg.__wbg_new_8a6f238a6ece86ea = function() {
        const ret = new Error();
        return ret;
    };
    imports.wbg.__wbg_newnoargs_105ed471475aaf50 = function(arg0, arg1) {
        const ret = new Function(getStringFromWasm0(arg0, arg1));
        return ret;
    };
    imports.wbg.__wbg_now_807e54c39636c349 = function() {
        const ret = Date.now();
        return ret;
    };
    imports.wbg.__wbg_requestAnimationFrame_d7fd890aaefc3246 = function() { return handleError(function (arg0, arg1) {
        const ret = arg0.requestAnimationFrame(arg1);
        return ret;
    }, arguments) };
    imports.wbg.__wbg_resume_35efdc4ffe13bf18 = function() { return handleError(function (arg0) {
        const ret = arg0.resume();
        return ret;
    }, arguments) };
    imports.wbg.__wbg_sampleRate_b7a06df362a2b6b3 = function(arg0) {
        const ret = arg0.sampleRate;
        return ret;
    };
    imports.wbg.__wbg_setAttribute_2704501201f15687 = function() { return handleError(function (arg0, arg1, arg2, arg3, arg4) {
        arg0.setAttribute(getStringFromWasm0(arg1, arg2), getStringFromWasm0(arg3, arg4));
    }, arguments) };
    imports.wbg.__wbg_setcontrols_01ad48dc4e49e469 = function(arg0, arg1) {
        arg0.controls = arg1 !== 0;
    };
    imports.wbg.__wbg_setfftSize_6d2de04a3049827b = function(arg0, arg1) {
        arg0.fftSize = arg1 >>> 0;
    };
    imports.wbg.__wbg_setonplay_378a0c3b1a72f222 = function(arg0, arg1) {
        arg0.onplay = arg1;
    };
    imports.wbg.__wbg_setsmoothingTimeConstant_97c7ef0c48dbcfac = function(arg0, arg1) {
        arg0.smoothingTimeConstant = arg1;
    };
    imports.wbg.__wbg_setsrc_3a759736e2659904 = function(arg0, arg1, arg2) {
        arg0.src = getStringFromWasm0(arg1, arg2);
    };
    imports.wbg.__wbg_settextContent_d29397f7b994d314 = function(arg0, arg1, arg2) {
        arg0.textContent = arg1 === 0 ? undefined : getStringFromWasm0(arg1, arg2);
    };
    imports.wbg.__wbg_stack_0ed75d68575b0f3c = function(arg0, arg1) {
        const ret = arg1.stack;
        const ptr1 = passStringToWasm0(ret, wasm.__wbindgen_malloc, wasm.__wbindgen_realloc);
        const len1 = WASM_VECTOR_LEN;
        getDataViewMemory0().setInt32(arg0 + 4 * 1, len1, true);
        getDataViewMemory0().setInt32(arg0 + 4 * 0, ptr1, true);
    };
    imports.wbg.__wbg_static_accessor_GLOBAL_88a902d13a557d07 = function() {
        const ret = typeof global === 'undefined' ? null : global;
        return isLikeNone(ret) ? 0 : addToExternrefTable0(ret);
    };
    imports.wbg.__wbg_static_accessor_GLOBAL_THIS_56578be7e9f832b0 = function() {
        const ret = typeof globalThis === 'undefined' ? null : globalThis;
        return isLikeNone(ret) ? 0 : addToExternrefTable0(ret);
    };
    imports.wbg.__wbg_static_accessor_SELF_37c5d418e4bf5819 = function() {
        const ret = typeof self === 'undefined' ? null : self;
        return isLikeNone(ret) ? 0 : addToExternrefTable0(ret);
    };
    imports.wbg.__wbg_static_accessor_WINDOW_5de37043a91a9c40 = function() {
        const ret = typeof window === 'undefined' ? null : window;
        return isLikeNone(ret) ? 0 : addToExternrefTable0(ret);
    };
    imports.wbg.__wbindgen_cb_drop = function(arg0) {
        const obj = arg0.original;
        if (obj.cnt-- == 1) {
            obj.a = 0;
            return true;
        }
        const ret = false;
        return ret;
    };
    imports.wbg.__wbindgen_closure_wrapper89 = function(arg0, arg1, arg2) {
        const ret = makeMutClosure(arg0, arg1, 18, __wbg_adapter_18);
        return ret;
    };
    imports.wbg.__wbindgen_init_externref_table = function() {
        const table = wasm.__wbindgen_export_2;
        const offset = table.grow(4);
        table.set(0, undefined);
        table.set(offset + 0, undefined);
        table.set(offset + 1, null);
        table.set(offset + 2, true);
        table.set(offset + 3, false);
        ;
    };
    imports.wbg.__wbindgen_is_undefined = function(arg0) {
        const ret = arg0 === undefined;
        return ret;
    };
    imports.wbg.__wbindgen_rethrow = function(arg0) {
        throw arg0;
    };
    imports.wbg.__wbindgen_string_new = function(arg0, arg1) {
        const ret = getStringFromWasm0(arg0, arg1);
        return ret;
    };
    imports.wbg.__wbindgen_throw = function(arg0, arg1) {
        throw new Error(getStringFromWasm0(arg0, arg1));
    };

    return imports;
}

function __wbg_init_memory(imports, memory) {

}

function __wbg_finalize_init(instance, module) {
    wasm = instance.exports;
    __wbg_init.__wbindgen_wasm_module = module;
    cachedDataViewMemory0 = null;
    cachedUint8ArrayMemory0 = null;


    wasm.__wbindgen_start();
    return wasm;
}

function initSync(module) {
    if (wasm !== undefined) return wasm;


    if (typeof module !== 'undefined') {
        if (Object.getPrototypeOf(module) === Object.prototype) {
            ({module} = module)
        } else {
            console.warn('using deprecated parameters for `initSync()`; pass a single object instead')
        }
    }

    const imports = __wbg_get_imports();

    __wbg_init_memory(imports);

    if (!(module instanceof WebAssembly.Module)) {
        module = new WebAssembly.Module(module);
    }

    const instance = new WebAssembly.Instance(module, imports);

    return __wbg_finalize_init(instance, module);
}

async function __wbg_init(module_or_path) {
    if (wasm !== undefined) return wasm;


    if (typeof module_or_path !== 'undefined') {
        if (Object.getPrototypeOf(module_or_path) === Object.prototype) {
            ({module_or_path} = module_or_path)
        } else {
            console.warn('using deprecated parameters for the initialization function; pass a single object instead')
        }
    }

    if (typeof module_or_path === 'undefined') {
        module_or_path = new URL('wasm_spectrometer_bg.wasm', import.meta.url);
    }
    const imports = __wbg_get_imports();

    if (typeof module_or_path === 'string' || (typeof Request === 'function' && module_or_path instanceof Request) || (typeof URL === 'function' && module_or_path instanceof URL)) {
        module_or_path = fetch(module_or_path);
    }

    __wbg_init_memory(imports);

    const { instance, module } = await __wbg_load(await module_or_path, imports);

    return __wbg_finalize_init(instance, module);
}

export { initSync };
export default __wbg_init;

```

## File: ../../../../../opt/caddy/html/reveal/public/wasm_spectrometer/index.html <a id="file-index-html"></a>

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebAssembly Audio Spectrometer</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 10px;
            background-color: #121212;
            color: #eaeaea;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
        }
        
        h3 {
            margin-bottom: 5px;
        }
        
        #container {
            width: 100%;
            max-width: 800px;
            border: 1px solid #333;
            border-radius: 8px;
            padding: 20px;
            background-color: #1e1e1e;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        
        #controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin: 10px 0;
            flex-wrap: wrap;
        }
        
        .source-selector {
            display: flex;
            gap: 12px;
            padding: 5px 10px;
            background-color: #2a2a2a;
            border-radius: 4px;
        }
        
        .radio-control, .checkbox-control {
            display: flex;
            align-items: center;
            gap: 5px;
            font-size: 0.9em;
        }
        
        button {
            background-color: #2a62c9;
            color: white;
            border: none;
            padding: 6px 12px;
            font-size: 0.9em;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.2s;
        }
        
        button:hover {
            background-color: #1a4db2;
        }
        
        #loading {
            text-align: center;
            margin: 20px;
            font-style: italic;
        }
        
        svg rect {
            fill: #4a8eff;
            stroke: none;
            transition: height 0.05s ease;
        }
        
        audio {
            width: 100%;
            margin: 10px 0; 
        }
        
        input[type="radio"], input[type="checkbox"] {
            cursor: pointer;
        }
        
        label {
            cursor: pointer;
            user-select: none;
        }
    </style>
</head>
<body>
    <h3>WebAssembly Audio Spectrometer</h3>

    <div id="container">
        <div id="loading">Loading WebAssembly module...</div>
        <!-- Add controls inside container, above where audio will be inserted -->
        <div id="controls">
            <div class="source-selector">
                <div class="radio-control">
                    <input type="radio" id="sample-audio" name="audio-source" checked>
                    <label for="sample-audio">Sample Audio</label>
                </div>
                <div class="radio-control">
                    <input type="radio" id="microphone" name="audio-source">
                    <label for="microphone">Microphone</label>
                </div>
            </div>
            
            <div class="checkbox-control">
                <input type="checkbox" id="spectrogram-toggle">
                <label for="spectrogram-toggle">Use Log Spectrogram</label>
            </div>
            
            <div class="checkbox-control">
                <input type="checkbox" id="debug-toggle">
                <label for="debug-toggle">Debug Mode</label>
            </div>
            
            <div class="checkbox-control">
                <input type="checkbox" id="pause-visualization">
                <label for="pause-visualization">Pause Visualization</label>
            </div>
        </div>
        <!-- The Rust module will create and append audio and SVG elements to the container -->
    </div>

    <script type="module">
        // Import the WebAssembly module with the new functions
        import init, {
            set_debug, 
            set_prevent_svg_update, 
            get_audio_context, 
            get_analyser, 
            set_use_log_spectrogram 
        } from './pkg/wasm_spectrometer.js';
        
        // Global development flag - set to true for development, false for production
        const dev = true;
        
        // Logging functions - only log if dev mode is enabled
        function reportError(error, message = "Error") {
            if (dev) {
                console.error(`[WASM Spectrometer] ${message}:`, error);
                if (error.stack) {
                    console.error(`[WASM Spectrometer] Stack trace:`, error.stack);
                }
            }
        }
        
        function reportInfo(message) {
            if (dev) {
                console.log(`[WASM Spectrometer] ${message}`);
            }
        }
        
        function reportWarning(message, data = null) {
            if (dev) {
                if (data) {
                    console.warn(`[WASM Spectrometer] ${message}:`, data);
                } else {
                    console.warn(`[WASM Spectrometer] ${message}`);
                }
            }
        }
                
        // Initialize variables
        const loadingElement = document.getElementById('loading');
        const container = document.getElementById('container');
        const debugToggle = document.getElementById('debug-toggle');
        const pauseVisualization = document.getElementById('pause-visualization');
        const sampleAudioRadio = document.getElementById('sample-audio');
        const microphoneRadio = document.getElementById('microphone');
        let audioElementSrc = './audio.mp3';
        let currentStream = null; // Track microphone stream for proper cleanup
        let isAudioSourceSwitching = false; // Flag to prevent concurrent switching
        let audioElementConnected = false; // Track if audio element already has a source connection
        let mediaElementSource = null;     // Store the MediaElementSource instance
    
        
        // Initialize the WebAssembly module with improved error handling
        async function initWasm() {
            try {
                reportInfo("Starting WebAssembly initialization...");
                // Enable panic hook to get better error messages
                await init({
                    // Enable better Rust panic messages in the console
                    debug: true
                });
                reportInfo("WebAssembly module loaded successfully");
                loadingElement.remove();
                
                // Only set up audio-related event listeners after WebAssembly has initialized
                setupEventListeners();
                
                // Don't autoplay anymore - let the user interact first
                setupInitialAudio();
            } catch (error) {
                loadingElement.textContent = "Failed to load WebAssembly module: " + error.message;
                reportError(error, "Failed to load WebAssembly module");
            }
        }
        
        // Setup initial audio element without playing
        function setupInitialAudio() {
            const audioElement = document.querySelector('audio');
            if (!audioElement) {
                reportError(new Error("Audio element not found"), "Initial audio setup failed");
                return;
            }
            
            // Just configure the source but don't play
            audioElement.src = audioElementSrc;
            audioElement.controls = true;
            
            // Add a message about using the controls
            const messageEl = document.createElement('div');
            messageEl.style.textAlign = 'center';
            messageEl.style.padding = '5px';
            messageEl.style.color = '#aaa';
            messageEl.style.fontSize = '0.9em';
            messageEl.textContent = 'Click play or select an audio source to begin';
            
            // Insert the message before the audio controls
            container.insertBefore(messageEl, audioElement.nextSibling);
        }
        
        // Function to switch to sample audio
        async function switchToSampleAudio() {
            // Prevent concurrent switching
            if (isAudioSourceSwitching) {
                reportWarning("Audio source switch in progress, please wait");
                return;
            }
            
            isAudioSourceSwitching = true;
            
            const audioElement = document.querySelector('audio');
            if (!audioElement) {
                reportError(new Error("Audio element not found"), "Sample audio playback failed");
                isAudioSourceSwitching = false;
                return;
            }
            
            reportInfo("Switching to sample audio");
            
            try {
                // Release microphone if it's currently being used
                await releaseMicrophone(audioElement);
                
                // Wait a bit to ensure clean disconnection
                await new Promise(resolve => setTimeout(resolve, 100));
                
                // Explicitly unmute audio (it may have been muted for mic input)
                audioElement.muted = false;
                audioElement.volume = 1.0;  // Ensure volume is up
                
                // Switch to file input
                audioElement.src = audioElementSrc;
                
                // Get the AudioContext and ensure it's running
                const audioContext = get_audio_context();
                const analyser = get_analyser();
                
                if (audioContext && audioContext.state === 'suspended') {
                    reportInfo("Resuming suspended audio context");
                    try {
                        await audioContext.resume();
                        reportInfo("Audio context resumed successfully");
                    } catch (e) {
                        reportWarning("Failed to resume audio context", e);
                    }
                }
                
                // Reset our connection tracking
                audioElementConnected = false;
                mediaElementSource = null;
                
                // Reconnect audio processing
                await reconnectAudioProcessing(audioElement);
                
                // Add a promise to handle playback
                try {
                    await audioElement.play();
                    reportInfo("Audio playback started successfully");
                } catch (error) {
                    // Check if it's an autoplay policy error
                    if (error.name === 'NotAllowedError') {
                        reportInfo("Autoplay prevented - user must click play");
                    } else {
                        reportError(error, "Playback failed");
                        alert("Playback failed. Check if the audio file exists.");
                    }
                }
            } catch (error) {
                reportError(error, "Error switching to sample audio");
            } finally {
                // Always reset the switching flag
                isAudioSourceSwitching = false;
            }
        }
        
        // Function to switch to microphone input
        async function switchToMicrophone() {
            // Prevent concurrent switching
            if (isAudioSourceSwitching) {
                reportWarning("Audio source switch in progress, please wait");
                return;
            }
            
            isAudioSourceSwitching = true;
            
            try {
                reportInfo("Switching to microphone input");
                
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                currentStream = stream; // Store for later cleanup
                
                const audioElement = document.querySelector('audio');
                if (!audioElement) {
                    throw new Error("Audio element not found for microphone");
                }
    
                // Pause any current audio playback
                audioElement.pause();
                
                // Get the AudioContext from Rust
                const audioContext = get_audio_context();
                const analyser = get_analyser();
                
                if (!audioContext || !analyser) {
                    throw new Error("Could not get audio context or analyser from Wasm");
                }
                
                // First, clean up any existing audio connections
                try {
                    analyser.disconnect();
                    reportInfo("Disconnected existing audio connections");
                } catch (e) {
                    // Ignore any disconnect errors
                    reportInfo("No existing connections to disconnect");
                }
                
                // Wait a bit to ensure clean disconnection
                await new Promise(resolve => setTimeout(resolve, 100));
                
                // Reset audio connection tracking when using microphone
                audioElementConnected = false;
                mediaElementSource = null;

                // Create a MediaStreamAudioSourceNode
                const micSource = audioContext.createMediaStreamSource(stream);
                
                // Connect the microphone source to the analyzer
                micSource.connect(analyser);
                analyser.connect(audioContext.destination);
                
                reportInfo("Microphone connected to audio analyzer");
                
                // Set the audio element's srcObject for visual feedback
                audioElement.srcObject = stream;
                audioElement.muted = true; // Prevent feedback
                
                try {
                    await audioElement.play();
                    reportInfo("Microphone visualization started");
                } catch (error) {
                    reportError(error, "Microphone visualization failed");
                    // Less critical if this fails as the audio analysis can still work
                }
                
            } catch (error) {
                reportError(error, "Error accessing microphone");
                alert("Could not access microphone: " + error.message);
                
                // Switch back to sample audio if mic fails
                sampleAudioRadio.checked = true;
                microphoneRadio.checked = false;
            } finally {
                // Always reset the switching flag
                isAudioSourceSwitching = false;
            }
        }
        
        // Helper function to release microphone
        async function releaseMicrophone(audioElement) {
            if (audioElement && audioElement.srcObject) {
                reportInfo("Releasing microphone stream");
                
                // Stop all tracks in the stream
                const tracks = audioElement.srcObject.getTracks();
                tracks.forEach(track => {
                    track.stop();
                    reportInfo(`Stopped track: ${track.kind}`);
                });
                
                // Clear the srcObject
                audioElement.srcObject = null;
                
                // Give the browser time to actually release the microphone
                await new Promise(resolve => setTimeout(resolve, 100));
            }
            
            // Also clean up the stored stream reference
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
                currentStream = null;
                
                // Give the browser time to actually release the microphone
                await new Promise(resolve => setTimeout(resolve, 100));
            }
            
            reportInfo("Microphone release completed");
        }
        
        // Helper function to reconnect audio processing
        async function reconnectAudioProcessing(audioElement) {
            // Reconnect audio processing if needed
            const audioContext = get_audio_context();
            const analyser = get_analyser();
            
            if (audioContext && analyser) {
                try {
                    // Ensure old connections are fully disconnected
                    try {
                        analyser.disconnect();
                        reportInfo("Disconnected existing analyzer connections");
                        
                        // Give the browser time to process the disconnection
                        await new Promise(resolve => setTimeout(resolve, 100));
                    } catch (e) {
                        // Ignore disconnection errors
                    }
                    
                    // Only create a new source if we don't have one or if we're reconnecting
                    if (!audioElementConnected || !mediaElementSource) {
                        try {
                            mediaElementSource = audioContext.createMediaElementSource(audioElement);
                            audioElementConnected = true;
                            reportInfo("Created new MediaElementSource");
                        } catch (e) {
                            if (e.name === 'InvalidStateError') {
                                reportInfo("Audio element already has a source - will try to reconnect");
                                // Try to get the existing connections working again
                                
                                // This is a workaround that might help in some browsers
                                audioElement.addEventListener('canplay', () => {
                                    try {
                                        analyser.connect(audioContext.destination);
                                        reportInfo("Reconnected analyzer to destination on canplay");
                                    } catch (e) {
                                        reportWarning("Failed to reconnect on canplay", e);
                                    }
                                }, { once: true });
                            } else {
                                throw e; // Re-throw if it's a different error
                            }
                        }
                    }
                    
                    // Connect source to analyzer if we have one
                    if (mediaElementSource) {
                        mediaElementSource.connect(analyser);
                        reportInfo("Connected media element source to analyzer");
                    }
                    
                    // Always ensure analyzer is connected to destination
                    analyser.connect(audioContext.destination);
                    reportInfo("Connected analyzer to audio destination");
                    
                    // Special handling for Safari and other browsers that need explicit connections
                    if (audioContext.state !== 'running') {
                        reportInfo(`Audio context state is ${audioContext.state}, attempting to resume`);
                        await audioContext.resume();
                    }
                    
                } catch (e) {
                    reportWarning("Could not reconnect audio source", e);
                    
                    // If all else fails, try a complete restart of audio
                    if (e.name === 'InvalidStateError') {
                        reportInfo("Audio element already connected - no need to reconnect");
                        
                        // Try to get audio playing anyway
                        try {
                            analyser.connect(audioContext.destination);
                            reportInfo("Forced analyzer connection to destination");
                        } catch (innerE) {
                            reportWarning("Failed to force connection", innerE);
                        }
                    }
                }
            }
        }
        
        // Set up event listeners
        function setupEventListeners() {
            debugToggle.addEventListener('change', (e) => {
                try {
                    set_debug(e.target.checked);
                    reportInfo(`Debug mode: ${e.target.checked}`);
                } catch (error) {
                    reportError(error, "Error setting debug mode");
                }
            });
        
            pauseVisualization.addEventListener('change', (e) => {
                try {
                    set_prevent_svg_update(e.target.checked);
                    reportInfo(`Visualization paused: ${e.target.checked}`);
                } catch (error) {
                    reportError(error, "Error toggling visualization");
                }
            });
            
            // Radio button handlers
            sampleAudioRadio.addEventListener('change', (e) => {
                if (e.target.checked) {
                    switchToSampleAudio();
                }
            });
            
            microphoneRadio.addEventListener('change', (e) => {
                if (e.target.checked) {
                    switchToMicrophone();
                }
            });

            // Add the spectrogram toggle handler
            const spectrogramToggle = document.getElementById('spectrogram-toggle');
            spectrogramToggle.addEventListener('change', (e) => {
                try {
                    set_use_log_spectrogram(e.target.checked);
                    reportInfo(`Spectrogram mode: ${e.target.checked ? 'Logarithmic' : 'Mel'}`);
                } catch (error) {
                    reportError(error, "Error setting spectrogram mode");
                }
            });
        }
        
        // Start initialization
        initWasm();
        
        // Clean up resources when the page is closed/refreshed
        window.addEventListener('beforeunload', () => {
            const audioElement = document.querySelector('audio');
            releaseMicrophone(audioElement);
        });
    </script>
</body>
</html>
```

## File: ../../../../../opt/caddy/html/reveal/public/wasm_spectrometer/Cargo.toml <a id="file-cargo-toml"></a>

```toml
[package]
name = "wasm_spectrometer"
version = "0.1.0"
edition = "2021"

[lib]
crate-type = ["cdylib", "rlib"]

[dependencies]
wasm-bindgen = "0.2.84"
web-sys = { version = "0.3.61", features = [
    "Window", 
    "Document", 
    "HtmlElement",
    "HtmlAudioElement", 
    "AudioContext", 
    "MediaElementAudioSourceNode",
    "AnalyserNode",
    "AudioNode",
    "AudioDestinationNode",
    "SvgElement",
    "SvgRectElement",
    "console"
]}
js-sys = "0.3.61"
lazy_static = "1.4.0"
console_error_panic_hook = { version = "0.1.7", optional = true }

[features]
default = ["console_error_panic_hook"]
```

