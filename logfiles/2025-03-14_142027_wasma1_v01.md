# Project: wasma1

## Table of Contents

- [index.html](#file-index-html)

## File: index.html <a id="file-index-html"></a>

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebAssembly Audio Spectrometer</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 10px;
            background-color: #121212;
            color: #eaeaea;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
        }
        
        h3 {
            margin-bottom: 5px;
        }
        
        #container {
            width: 100%;
            max-width: 800px;
            border: 1px solid #333;
            border-radius: 8px;
            padding: 20px;
            background-color: #1e1e1e;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        
        #controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin: 10px 0;
            flex-wrap: wrap;
        }
        
        .source-selector {
            display: flex;
            gap: 12px;
            padding: 5px 10px;
            background-color: #2a2a2a;
            border-radius: 4px;
        }
        
        .radio-control, .checkbox-control {
            display: flex;
            align-items: center;
            gap: 5px;
            font-size: 0.9em;
        }
        
        button {
            background-color: #2a62c9;
            color: white;
            border: none;
            padding: 6px 12px;
            font-size: 0.9em;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.2s;
        }
        
        button:hover {
            background-color: #1a4db2;
        }
        
        #loading {
            text-align: center;
            margin: 20px;
            font-style: italic;
        }
        
        svg rect {
            fill: #4a8eff;
            stroke: none;
            transition: height 0.05s ease;
        }
        
        audio {
            width: 100%;
            margin: 10px 0; 
        }
        
        input[type="radio"], input[type="checkbox"] {
            cursor: pointer;
        }
        
        label {
            cursor: pointer;
            user-select: none;
        }
    </style>
</head>
<body>
    <h3>WebAssembly Audio Spectrometer</h3>

    <div id="container">
        <div id="loading">Loading WebAssembly module...</div>
        <svg id="visualization" width="800" height="400"></svg>
        <!-- Add controls inside container -->
        <div id="controls">
            <div class="source-selector">
                <div class="radio-control">
                    <input type="radio" id="sample-audio" name="audio-source" checked>
                    <label for="sample-audio">Sample Audio</label>
                </div>
                <div class="radio-control">
                    <input type="radio" id="microphone" name="audio-source">
                    <label for="microphone">Microphone</label>
                </div>
            </div>
            
            <div class="checkbox-control">
                <input type="checkbox" id="spectrogram-toggle">
                <label for="spectrogram-toggle">Use Log Spectrogram</label>
            </div>
            
            <div class="checkbox-control">
                <input type="checkbox" id="debug-toggle">
                <label for="debug-toggle">Debug Mode</label>
            </div>
            
            <div class="checkbox-control">
                <input type="checkbox" id="pause-visualization">
                <label for="pause-visualization">Pause Visualization</label>
            </div>
            
            <!-- Add visualization selector -->
            <div class="source-selector">
                <div class="radio-control">
                    <input type="radio" id="viz-bars" name="visualization-type" checked>
                    <label for="viz-bars">Bars</label>
                </div>
                <div class="radio-control">
                    <input type="radio" id="viz-circle" name="visualization-type">
                    <label for="viz-circle">Circle</label>
                </div>
                <div class="radio-control">
                    <input type="radio" id="viz-spectrogram" name="visualization-type">
                    <label for="viz-spectrogram">Spectrogram</label>
                </div>
            </div>
        </div>
        <!-- The Rust module will append audio elements here -->
    </div>

    <script type="module">
        // Import the WebAssembly module with the new functions
        import init, {
            set_debug, 
            set_prevent_svg_update, 
            get_audio_context, 
            get_analyser, 
            set_use_log_spectrogram,
            set_visualization
        } from './pkg/awesome_wasm_spectrometer.js';
        
        // Global development flag - set to true for development, false for production
        const dev = true;
        
        // Logging functions - only log if dev mode is enabled
        function reportError(error, message = "Error") {
            if (dev) {
                console.error(`[WASM Spectrometer] ${message}:`, error);
                if (error.stack) {
                    console.error(`[WASM Spectrometer] Stack trace:`, error.stack);
                }
            }
        }
        
        function reportInfo(message) {
            if (dev) {
                console.log(`[WASM Spectrometer] ${message}`);
            }
        }
        
        function reportWarning(message, data = null) {
            if (dev) {
                if (data) {
                    console.warn(`[WASM Spectrometer] ${message}:`, data);
                } else {
                    console.warn(`[WASM Spectrometer] ${message}`);
                }
            }
        }
                
        // Initialize variables
        const loadingElement = document.getElementById('loading');
        const container = document.getElementById('container');
        const debugToggle = document.getElementById('debug-toggle');
        const pauseVisualization = document.getElementById('pause-visualization');
        const sampleAudioRadio = document.getElementById('sample-audio');
        const microphoneRadio = document.getElementById('microphone');
        let audioElementSrc = './audio.mp3';
        let currentStream = null; // Track microphone stream for proper cleanup
        let isAudioSourceSwitching = false; // Flag to prevent concurrent switching
        let audioElementConnected = false; // Track if audio element already has a source connection
        let mediaElementSource = null;     // Store the MediaElementSource instance
    
        // Initialize the WebAssembly module with improved error handling
        async function initWasm() {
            try {
                reportInfo("Starting WebAssembly initialization...");
                // Enable panic hook to get better error messages
                await init({
                    // Enable better Rust panic messages in the console
                    debug: true
                });
                reportInfo("WebAssembly module loaded successfully");
                loadingElement.remove();
                
                // Set up audio-related event listeners after WebAssembly initialization
                setupEventListeners();
                
                // Don't autoplay - let the user interact first
                setupInitialAudio();
            } catch (error) {
                loadingElement.textContent = "Failed to load WebAssembly module: " + error.message;
                reportError(error, "Failed to load WebAssembly module");
            }
        }
        
        // Setup initial audio element without playing
        function setupInitialAudio() {
            const audioElement = document.querySelector('audio');
            if (!audioElement) {
                reportError(new Error("Audio element not found"), "Initial audio setup failed");
                return;
            }
            
            // Just configure the source but don't play
            audioElement.src = audioElementSrc;
            
            // Connect audio element to the analyzer
            reconnectAudioProcessing(audioElement);
            
            // Add a message about using the controls
            const messageEl = document.createElement('div');
            messageEl.style.textAlign = 'center';
            messageEl.style.padding = '5px';
            messageEl.style.color = '#aaa';
            messageEl.style.fontSize = '0.9em';
            messageEl.textContent = 'Click play or select an audio source to begin';
            
            // Insert the message before the audio controls
            container.insertBefore(messageEl, audioElement.nextSibling);
        }
        
        // Function to switch to sample audio
        async function switchToSampleAudio() {
            if (isAudioSourceSwitching) {
                reportWarning("Audio source switch in progress, please wait");
                return;
            }
            
            isAudioSourceSwitching = true;
            
            const audioElement = document.querySelector('audio');
            if (!audioElement) {
                reportError(new Error("Audio element not found"), "Sample audio playback failed");
                isAudioSourceSwitching = false;
                return;
            }
            
            reportInfo("Switching to sample audio");
            
            try {
                await releaseMicrophone(audioElement);
                await new Promise(resolve => setTimeout(resolve, 100));
                audioElement.muted = false;
                audioElement.volume = 1.0;
                audioElement.src = audioElementSrc;
                
                const audioContext = get_audio_context();
                const analyser = get_analyser();
                
                if (audioContext && audioContext.state === 'suspended') {
                    reportInfo("Resuming suspended audio context");
                    try {
                        await audioContext.resume();
                        reportInfo("Audio context resumed successfully");
                    } catch (e) {
                        reportWarning("Failed to resume audio context", e);
                    }
                }
                
                audioElementConnected = false;
                mediaElementSource = null;
                await reconnectAudioProcessing(audioElement);
                
                try {
                    await audioElement.play();
                    reportInfo("Audio playback started successfully");
                } catch (error) {
                    if (error.name === 'NotAllowedError') {
                        reportInfo("Autoplay prevented - user must click play");
                    } else {
                        reportError(error, "Playback failed");
                        alert("Playback failed. Check if the audio file exists.");
                    }
                }
            } catch (error) {
                reportError(error, "Error switching to sample audio");
            } finally {
                isAudioSourceSwitching = false;
            }
        }
        
        // Function to switch to microphone input
        async function switchToMicrophone() {
            if (isAudioSourceSwitching) {
                reportWarning("Audio source switch in progress, please wait");
                return;
            }
            
            isAudioSourceSwitching = true;
            
            try {
                reportInfo("Switching to microphone input");
                
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                currentStream = stream;
                
                const audioElement = document.querySelector('audio');
                if (!audioElement) {
                    throw new Error("Audio element not found for microphone");
                }
    
                audioElement.pause();
                
                const audioContext = get_audio_context();
                const analyser = get_analyser();
                
                if (!audioContext || !analyser) {
                    throw new Error("Could not get audio context or analyser from Wasm");
                }
                
                try {
                    analyser.disconnect();
                    reportInfo("Disconnected existing audio connections");
                } catch (e) {
                    reportInfo("No existing connections to disconnect");
                }
                
                await new Promise(resolve => setTimeout(resolve, 100));
                audioElementConnected = false;
                mediaElementSource = null;

                const micSource = audioContext.createMediaStreamSource(stream);
                micSource.connect(analyser);
                analyser.connect(audioContext.destination);
                
                reportInfo("Microphone connected to audio analyzer");
                audioElement.srcObject = stream;
                audioElement.muted = true;
                
                try {
                    await audioElement.play();
                    reportInfo("Microphone visualization started");
                } catch (error) {
                    reportError(error, "Microphone visualization failed");
                }
                
            } catch (error) {
                reportError(error, "Error accessing microphone");
                alert("Could not access microphone: " + error.message);
                sampleAudioRadio.checked = true;
                microphoneRadio.checked = false;
            } finally {
                isAudioSourceSwitching = false;
            }
        }
        
        // Helper function to release microphone
        async function releaseMicrophone(audioElement) {
            if (audioElement && audioElement.srcObject) {
                reportInfo("Releasing microphone stream");
                const tracks = audioElement.srcObject.getTracks();
                tracks.forEach(track => {
                    track.stop();
                    reportInfo(`Stopped track: ${track.kind}`);
                });
                audioElement.srcObject = null;
                await new Promise(resolve => setTimeout(resolve, 100));
            }
            
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
                currentStream = null;
                await new Promise(resolve => setTimeout(resolve, 100));
            }
            
            reportInfo("Microphone release completed");
        }
        
        // Helper function to reconnect audio processing
        async function reconnectAudioProcessing(audioElement) {
            const audioContext = get_audio_context();
            const analyser = get_analyser();
            
            if (audioContext && analyser) {
                try {
                    try {
                        analyser.disconnect();
                        reportInfo("Disconnected existing analyzer connections");
                        await new Promise(resolve => setTimeout(resolve, 100));
                    } catch (e) {
                        // Ignore disconnection errors
                    }
                    
                    if (!audioElementConnected || !mediaElementSource) {
                        try {
                            mediaElementSource = audioContext.createMediaElementSource(audioElement);
                            audioElementConnected = true;
                            reportInfo("Created new MediaElementSource");
                        } catch (e) {
                            if (e.name === 'InvalidStateError') {
                                reportInfo("Audio element already has a source - will try to reconnect");
                                audioElement.addEventListener('canplay', () => {
                                    try {
                                        analyser.connect(audioContext.destination);
                                        reportInfo("Reconnected analyzer to destination on canplay");
                                    } catch (e) {
                                        reportWarning("Failed to reconnect on canplay", e);
                                    }
                                }, { once: true });
                            } else {
                                throw e;
                            }
                        }
                    }
                    
                    if (mediaElementSource) {
                        mediaElementSource.connect(analyser);
                        reportInfo("Connected media element source to analyzer");
                    }
                    analyser.connect(audioContext.destination);
                    reportInfo("Connected analyzer to audio destination");
                    
                    if (audioContext.state !== 'running') {
                        reportInfo(`Audio context state is ${audioContext.state}, attempting to resume`);
                        await audioContext.resume();
                    }
                } catch (e) {
                    reportWarning("Could not reconnect audio source", e);
                    if (e.name === 'InvalidStateError') {
                        reportInfo("Audio element already connected - no need to reconnect");
                        try {
                            analyser.connect(audioContext.destination);
                            reportInfo("Forced analyzer connection to destination");
                        } catch (innerE) {
                            reportWarning("Failed to force connection", innerE);
                        }
                    }
                }
            }
        }
        
        // Set up event listeners
        function setupEventListeners() {
            debugToggle.addEventListener('change', (e) => {
                try {
                    set_debug(e.target.checked);
                    reportInfo(`Debug mode: ${e.target.checked}`);
                } catch (error) {
                    reportError(error, "Error setting debug mode");
                }
            });
        
            pauseVisualization.addEventListener('change', (e) => {
                try {
                    set_prevent_svg_update(e.target.checked);
                    reportInfo(`Visualization paused: ${e.target.checked}`);
                } catch (error) {
                    reportError(error, "Error toggling visualization");
                }
            });
            
            sampleAudioRadio.addEventListener('change', (e) => {
                if (e.target.checked) {
                    switchToSampleAudio();
                }
            });
            
            microphoneRadio.addEventListener('change', (e) => {
                if (e.target.checked) {
                    switchToMicrophone();
                }
            });

            const spectrogramToggle = document.getElementById('spectrogram-toggle');
            spectrogramToggle.addEventListener('change', (e) => {
                try {
                    set_use_log_spectrogram(e.target.checked);
                    reportInfo(`Spectrogram mode: ${e.target.checked ? 'Logarithmic' : 'Mel'}`);
                } catch (error) {
                    reportError(error, "Error setting spectrogram mode");
                }
            });
            
            // Add event listeners for visualization type selection
            const vizBars = document.getElementById('viz-bars');
            const vizCircle = document.getElementById('viz-circle');
            const vizSpectrogram = document.getElementById('viz-spectrogram');
            
            vizBars.addEventListener('change', (e) => {
                if (e.target.checked) {
                    try {
                        set_visualization(0);
                        reportInfo("Switched to Bars visualization");
                    } catch (error) {
                        reportError(error, "Failed to switch visualization");
                    }
                }
            });
            
            vizCircle.addEventListener('change', (e) => {
                if (e.target.checked) {
                    try {
                        set_visualization(1);
                        reportInfo("Switched to Circle visualization");
                    } catch (error) {
                        reportError(error, "Failed to switch visualization");
                    }
                }
            });
            
            vizSpectrogram.addEventListener('change', (e) => {
                if (e.target.checked) {
                    try {
                        set_visualization(2);
                        reportInfo("Switched to Spectrogram visualization");
                    } catch (error) {
                        reportError(error, "Failed to switch visualization");
                    }
                }
            });
            
            // Add event listener for audio playback
            const audioElement = document.querySelector('audio');
            if (audioElement) {
                audioElement.addEventListener('play', async () => {
                    const audioContext = get_audio_context();
                    if (audioContext && audioContext.state === 'suspended') {
                        try {
                            reportInfo("Resuming audio context on play");
                            await audioContext.resume();
                        } catch (error) {
                            reportError(error, "Failed to resume audio context");
                        }
                    }
                });
            }
        }
        
        // Start initialization after DOM is fully loaded
        document.addEventListener('DOMContentLoaded', () => {
            initWasm();
        });
        
        // Clean up resources when the page is closed/refreshed
        window.addEventListener('beforeunload', () => {
            const audioElement = document.querySelector('audio');
            releaseMicrophone(audioElement);
        });
    </script>
</body>
</html>
```

